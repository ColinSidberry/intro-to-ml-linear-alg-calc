{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 Solution: Dot Products - The Heartbeat of Machine Learning\n",
    "\n",
    "This notebook contains complete solutions to all tasks in Problem 2. Use this to check your work or understand the intended approaches.\n",
    "\n",
    "## Key Learning Points\n",
    "- Dot products measure alignment between feature and weight vectors\n",
    "- Different weights create different decision patterns\n",
    "- Geometric intuition helps understand mathematical operations\n",
    "- The sigmoid function transforms raw scores into probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Import our custom utilities\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "from data_generators import load_sports_dataset\n",
    "from visualization import plot_feature_space_2d, plot_decision_boundary\n",
    "\n",
    "# Load our data from Problem 1\n",
    "features, labels, feature_names, texts = load_sports_dataset()\n",
    "\n",
    "print(\"Continuing with our sports tweets:\")\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Feature names: {feature_names}\")\n",
    "print(f\"\\nOur key example:\")\n",
    "print(f\"Text: 'Go Dolphins!' → Features: {features[0]} → True label: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 Solution: Computing Dot Products by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our \"Go Dolphins!\" feature vector\n",
    "go_dolphins_features = np.array([2, 1, 1])  # [word_count, has_team, has_exclamation]\n",
    "\n",
    "# Let's try different weight vectors and see what predictions they give\n",
    "weight_examples = {\n",
    "    \"Random weights\": np.array([0.1, 0.2, 0.1]),\n",
    "    \"Team-focused\": np.array([0.1, 0.8, 0.1]),\n",
    "    \"Excitement-focused\": np.array([0.1, 0.1, 0.8]),\n",
    "    \"Word-count focused\": np.array([0.8, 0.1, 0.1]),\n",
    "    \"Balanced weights\": np.array([0.3, 0.3, 0.4])\n",
    "}\n",
    "\n",
    "print(\"DOT PRODUCT CALCULATIONS FOR 'GO DOLPHINS!'\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Feature vector: {go_dolphins_features}\")\n",
    "print(f\"Features: [word_count={go_dolphins_features[0]}, has_team={go_dolphins_features[1]}, has_exclamation={go_dolphins_features[2]}]\")\n",
    "print()\n",
    "\n",
    "for name, weights in weight_examples.items():\n",
    "    # Manual dot product calculation\n",
    "    dot_product = (go_dolphins_features[0] * weights[0] + \n",
    "                  go_dolphins_features[1] * weights[1] + \n",
    "                  go_dolphins_features[2] * weights[2])\n",
    "    \n",
    "    # Verify with numpy\n",
    "    numpy_result = np.dot(go_dolphins_features, weights)\n",
    "    \n",
    "    print(f\"{name:<20} | Weights: {weights} | Dot Product: {dot_product:.3f}\")\n",
    "    \n",
    "    # Show the calculation step by step\n",
    "    calculation = f\"({go_dolphins_features[0]}×{weights[0]:.1f}) + ({go_dolphins_features[1]}×{weights[1]:.1f}) + ({go_dolphins_features[2]}×{weights[2]:.1f})\"\n",
    "    print(f\"{'':20} | Calculation: {calculation} = {dot_product:.3f}\")\n",
    "    print(f\"{'':20} | NumPy verification: {numpy_result:.3f} {'✅' if abs(dot_product - numpy_result) < 1e-10 else '❌'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement manual dot product function\n",
    "def manual_dot_product(vector_a: np.ndarray, vector_b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate dot product without using numpy's built-in function.\n",
    "    \"\"\"\n",
    "    if len(vector_a) != len(vector_b):\n",
    "        raise ValueError(\"Vectors must have the same length\")\n",
    "    \n",
    "    result = 0.0\n",
    "    for i in range(len(vector_a)):\n",
    "        result += vector_a[i] * vector_b[i]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Alternative implementation using list comprehension\n",
    "def manual_dot_product_v2(vector_a: np.ndarray, vector_b: np.ndarray) -> float:\n",
    "    \"\"\"Alternative implementation using list comprehension\"\"\"\n",
    "    return sum(a * b for a, b in zip(vector_a, vector_b))\n",
    "\n",
    "# Test implementations\n",
    "test_weights = np.array([0.3, 0.5, 0.4])\n",
    "manual_result = manual_dot_product(go_dolphins_features, test_weights)\n",
    "manual_result_v2 = manual_dot_product_v2(go_dolphins_features, test_weights)\n",
    "numpy_result = np.dot(go_dolphins_features, test_weights)\n",
    "\n",
    "print(f\"Manual calculation (loop): {manual_result:.6f}\")\n",
    "print(f\"Manual calculation (comprehension): {manual_result_v2:.6f}\")\n",
    "print(f\"NumPy's calculation: {numpy_result:.6f}\")\n",
    "print(f\"All methods match: {'✅' if abs(manual_result - numpy_result) < 1e-10 and abs(manual_result_v2 - numpy_result) < 1e-10 else '❌'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 Solution: Geometric Interpretation - Vector Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric analysis of dot products\n",
    "def analyze_vector_alignment(features: np.ndarray, weights: np.ndarray, name: str = \"\"):\n",
    "    \"\"\"\n",
    "    Analyze the geometric relationship between feature and weight vectors.\n",
    "    \"\"\"\n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(features, weights)\n",
    "    \n",
    "    # Calculate magnitudes\n",
    "    features_magnitude = np.linalg.norm(features)\n",
    "    weights_magnitude = np.linalg.norm(weights)\n",
    "    \n",
    "    # Calculate angle between vectors\n",
    "    cos_angle = dot_product / (features_magnitude * weights_magnitude)\n",
    "    # Clip to handle numerical errors\n",
    "    cos_angle = np.clip(cos_angle, -1, 1)\n",
    "    angle_radians = np.arccos(cos_angle)\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "    \n",
    "    print(f\"Analysis for {name}:\")\n",
    "    print(f\"  Features vector: {features}\")\n",
    "    print(f\"  Weights vector:  {weights}\")\n",
    "    print(f\"  Dot product:     {dot_product:.3f}\")\n",
    "    print(f\"  Features magnitude: {features_magnitude:.3f}\")\n",
    "    print(f\"  Weights magnitude:  {weights_magnitude:.3f}\")\n",
    "    print(f\"  cos(θ): {cos_angle:.3f}\")\n",
    "    print(f\"  Angle between vectors: {angle_degrees:.1f}°\")\n",
    "    \n",
    "    if angle_degrees < 45:\n",
    "        interpretation = \"Well aligned (strong positive signal)\"\n",
    "    elif angle_degrees < 90:\n",
    "        interpretation = \"Moderately aligned (moderate positive signal)\"\n",
    "    elif angle_degrees < 135:\n",
    "        interpretation = \"Moderately misaligned (moderate negative signal)\"\n",
    "    else:\n",
    "        interpretation = \"Poorly aligned (strong negative signal)\"\n",
    "    \n",
    "    print(f\"  Interpretation: {interpretation}\")\n",
    "    print()\n",
    "    \n",
    "    return dot_product, angle_degrees\n",
    "\n",
    "# Test with different weight configurations\n",
    "print(\"GEOMETRIC ANALYSIS OF VECTOR ALIGNMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Case 1: Well-aligned weights (similar pattern to features)\n",
    "aligned_weights = np.array([0.4, 0.3, 0.3])  # Emphasizes all features proportionally\n",
    "analyze_vector_alignment(go_dolphins_features, aligned_weights, \"Well-aligned weights\")\n",
    "\n",
    "# Case 2: Perpendicular weights\n",
    "# To create perpendicular vectors, we need weights such that dot product = 0\n",
    "# For features [2, 1, 1], we need 2*w1 + 1*w2 + 1*w3 = 0\n",
    "# Let's use w1 = 0, w2 = 1, w3 = -1\n",
    "perpendicular_weights = np.array([0.0, 1.0, -1.0])\n",
    "analyze_vector_alignment(go_dolphins_features, perpendicular_weights, \"Perpendicular weights\")\n",
    "\n",
    "# Case 3: Opposite alignment\n",
    "opposite_weights = np.array([-0.4, -0.3, -0.3])  # All negative\n",
    "analyze_vector_alignment(go_dolphins_features, opposite_weights, \"Opposite weights\")\n",
    "\n",
    "# Case 4: Team-focused weights\n",
    "team_weights = np.array([0.1, 0.9, 0.1])  # Heavy emphasis on team feature\n",
    "analyze_vector_alignment(go_dolphins_features, team_weights, \"Team-focused weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the relationship between angle and prediction strength\n",
    "def create_weight_at_angle(reference_vector: np.ndarray, target_angle_degrees: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a weight vector that makes approximately the target angle with reference vector.\n",
    "    \"\"\"\n",
    "    target_radians = np.radians(target_angle_degrees)\n",
    "    \n",
    "    if target_angle_degrees == 0:\n",
    "        # Parallel - same direction\n",
    "        return reference_vector / np.linalg.norm(reference_vector)\n",
    "    elif target_angle_degrees == 180:\n",
    "        # Anti-parallel - opposite direction\n",
    "        return -reference_vector / np.linalg.norm(reference_vector)\n",
    "    elif target_angle_degrees == 90:\n",
    "        # Perpendicular - use the perpendicular we found\n",
    "        return np.array([0.0, 1.0, -1.0]) / np.linalg.norm(np.array([0.0, 1.0, -1.0]))\n",
    "    else:\n",
    "        # Approximate other angles by mixing parallel and perpendicular components\n",
    "        parallel_component = reference_vector / np.linalg.norm(reference_vector)\n",
    "        perpendicular_component = np.array([0.0, 1.0, -1.0]) / np.linalg.norm(np.array([0.0, 1.0, -1.0]))\n",
    "        \n",
    "        # Mix based on desired angle\n",
    "        parallel_weight = np.cos(target_radians)\n",
    "        perp_weight = np.sin(target_radians)\n",
    "        \n",
    "        result = parallel_weight * parallel_component + perp_weight * perpendicular_component\n",
    "        return result / np.linalg.norm(result)\n",
    "\n",
    "# Test specific angles\n",
    "angles_to_test = [0, 30, 60, 90, 120, 150, 180]\n",
    "predictions = []\n",
    "actual_angles = []\n",
    "\n",
    "print(\"EXPLORING ANGLE vs PREDICTION RELATIONSHIP\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for target_angle in angles_to_test:\n",
    "    weights = create_weight_at_angle(go_dolphins_features, target_angle)\n",
    "    dot_product, actual_angle = analyze_vector_alignment(go_dolphins_features, weights, f\"Target {target_angle}°\")\n",
    "    \n",
    "    predictions.append(dot_product)\n",
    "    actual_angles.append(actual_angle)\n",
    "\n",
    "# Plot the relationship\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(actual_angles, predictions, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Angle between vectors (degrees)')\n",
    "plt.ylabel('Dot Product (Prediction)')\n",
    "plt.title('Angle vs Prediction Strength')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.5, label='Zero prediction')\n",
    "plt.axvline(x=90, color='r', linestyle='--', alpha=0.5, label='Perpendicular')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Show cosine relationship\n",
    "theoretical_angles = np.linspace(0, 180, 100)\n",
    "theoretical_cos = np.cos(np.radians(theoretical_angles))\n",
    "plt.plot(theoretical_angles, theoretical_cos, 'r--', label='cos(angle)', linewidth=2)\n",
    "\n",
    "# Normalize our predictions to compare with cosine\n",
    "features_mag = np.linalg.norm(go_dolphins_features)\n",
    "normalized_predictions = [p / features_mag for p in predictions]  # Assuming unit weight vectors\n",
    "plt.plot(actual_angles, normalized_predictions, 'bo-', label='Normalized predictions', markersize=8)\n",
    "\n",
    "plt.xlabel('Angle (degrees)')\n",
    "plt.ylabel('Normalized value')\n",
    "plt.title('Cosine Relationship Verification')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Dot product = |a| × |b| × cos(angle)\")\n",
    "print(\"- When vectors are aligned (0°), prediction is strongest and positive\")\n",
    "print(\"- When vectors are perpendicular (90°), prediction is zero\")\n",
    "print(\"- When vectors are opposite (180°), prediction is strongest but negative\")\n",
    "print(\"- This cosine relationship is fundamental to understanding ML predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Solution: Testing Different Weight Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different weight strategies\n",
    "weight_strategies = {\n",
    "    \"Equal weights\": np.array([0.33, 0.33, 0.33]),\n",
    "    \"Team-focused\": np.array([0.1, 0.8, 0.1]),\n",
    "    \"Excitement-focused\": np.array([0.1, 0.1, 0.8]),\n",
    "    \"Length-focused\": np.array([0.8, 0.1, 0.1]),\n",
    "    \"Optimized-guess\": np.array([0.2, 0.5, 0.6]),  # Weighted toward team + excitement\n",
    "    \"Anti-pattern\": np.array([-0.3, 0.5, -0.4]),  # Some negative weights\n",
    "}\n",
    "\n",
    "def evaluate_weight_strategy(features: np.ndarray, labels: np.ndarray, \n",
    "                           weights: np.ndarray, texts: List[str], strategy_name: str):\n",
    "    \"\"\"\n",
    "    Evaluate how well a weight strategy performs on all tweets.\n",
    "    \"\"\"\n",
    "    # Calculate predictions for all tweets\n",
    "    predictions = features @ weights  # Matrix multiplication = dot products for all rows\n",
    "    \n",
    "    # Convert to binary predictions (positive if > 0.5)\n",
    "    binary_predictions = (predictions > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(binary_predictions == labels)\n",
    "    \n",
    "    # Calculate other metrics\n",
    "    true_positives = np.sum((binary_predictions == 1) & (labels == 1))\n",
    "    false_positives = np.sum((binary_predictions == 1) & (labels == 0))\n",
    "    true_negatives = np.sum((binary_predictions == 0) & (labels == 0))\n",
    "    false_negatives = np.sum((binary_predictions == 0) & (labels == 1))\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Show detailed results\n",
    "    print(f\"\\nSTRATEGY: {strategy_name}\")\n",
    "    print(f\"Weights: {weights}\")\n",
    "    print(f\"Accuracy: {accuracy:.1%} | Precision: {precision:.1%} | Recall: {recall:.1%} | F1: {f1_score:.1%}\")\n",
    "    print(\"\\nDetailed predictions:\")\n",
    "    \n",
    "    for i, (text, true_label, pred_score, pred_binary) in enumerate(\n",
    "        zip(texts, labels, predictions, binary_predictions)):\n",
    "        \n",
    "        correct = \"✓\" if pred_binary == true_label else \"✗\"\n",
    "        true_sentiment = \"Pos\" if true_label == 1 else \"Neg\"\n",
    "        pred_sentiment = \"Pos\" if pred_binary == 1 else \"Neg\"\n",
    "        confidence = \"High\" if abs(pred_score - 0.5) > 0.3 else \"Low\"\n",
    "        \n",
    "        print(f\"  {correct} '{text:<25}' | True: {true_sentiment} | Pred: {pred_sentiment} (score: {pred_score:.3f}, {confidence})\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'predictions': predictions,\n",
    "        'weights': weights\n",
    "    }\n",
    "\n",
    "# Test each strategy and compare results\n",
    "print(\"COMPARING WEIGHT STRATEGIES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "strategy_results = {}\n",
    "\n",
    "for name, weights in weight_strategies.items():\n",
    "    results = evaluate_weight_strategy(features, labels, weights, texts, name)\n",
    "    strategy_results[name] = results\n",
    "\n",
    "# Rank strategies by performance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATEGY RANKINGS (by accuracy):\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ranked_strategies = sorted(strategy_results.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
    "for i, (name, results) in enumerate(ranked_strategies, 1):\n",
    "    print(f\"{i}. {name:<20} | Acc: {results['accuracy']:.1%} | F1: {results['f1_score']:.1%} | Weights: {results['weights']}\")\n",
    "\n",
    "# Analyze why certain strategies work better\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATEGY ANALYSIS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_strategy = ranked_strategies[0]\n",
    "worst_strategy = ranked_strategies[-1]\n",
    "\n",
    "print(f\"\\nBest strategy: {best_strategy[0]}\")\n",
    "print(f\"  Weights: {best_strategy[1]['weights']}\")\n",
    "print(f\"  Why it works: High weight on 'has_team' ({best_strategy[1]['weights'][1]:.1f}) and 'has_exclamation' ({best_strategy[1]['weights'][2]:.1f})\")\n",
    "print(f\"  This makes sense because positive sports tweets often mention teams and show excitement!\")\n",
    "\n",
    "print(f\"\\nWorst strategy: {worst_strategy[0]}\")\n",
    "print(f\"  Weights: {worst_strategy[1]['weights']}\")\n",
    "print(f\"  Why it fails: Negative weights can create confusing signals\")\n",
    "print(f\"  The anti-pattern weights go against natural sentiment indicators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how different strategies create different decision boundaries\n",
    "# We'll create a 2D visualization using the first two features\n",
    "\n",
    "# Extract first two features for visualization\n",
    "features_2d = features[:, :2]  # [word_count, has_team]\n",
    "\n",
    "# Create grid for decision boundary visualization\n",
    "x_min, x_max = features_2d[:, 0].min() - 0.5, features_2d[:, 0].max() + 0.5\n",
    "y_min, y_max = features_2d[:, 1].min() - 0.1, features_2d[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Plot decision boundaries for top 3 strategies\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (strategy_name, results) in enumerate(ranked_strategies[:3]):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Use only first two weights for 2D visualization (ignore exclamation weight)\n",
    "    weights_2d = results['weights'][:2]\n",
    "    \n",
    "    # Calculate decision boundary: w1*x1 + w2*x2 = 0.5 (threshold)\n",
    "    # Rearranged: x2 = (0.5 - w1*x1) / w2\n",
    "    if abs(weights_2d[1]) > 1e-10:  # Avoid division by zero\n",
    "        boundary_x = np.linspace(x_min, x_max, 100)\n",
    "        boundary_y = (0.5 - weights_2d[0] * boundary_x) / weights_2d[1]\n",
    "        \n",
    "        # Only plot boundary within our range\n",
    "        valid_mask = (boundary_y >= y_min) & (boundary_y <= y_max)\n",
    "        if np.any(valid_mask):\n",
    "            ax.plot(boundary_x[valid_mask], boundary_y[valid_mask], 'b-', linewidth=3, \n",
    "                   label=f'Decision Boundary\\n(accuracy: {results[\"accuracy\"]:.1%})')\n",
    "    \n",
    "    # Create background color map for decision regions\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    # Add third feature (exclamation) as average value for visualization\n",
    "    avg_exclamation = np.mean(features[:, 2])\n",
    "    grid_points_3d = np.column_stack([grid_points, np.full(grid_points.shape[0], avg_exclamation)])\n",
    "    \n",
    "    Z = grid_points_3d @ results['weights']\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision regions\n",
    "    ax.contourf(xx, yy, Z, levels=[Z.min(), 0.5, Z.max()], colors=['lightcoral', 'lightblue'], alpha=0.3)\n",
    "    ax.contour(xx, yy, Z, levels=[0.5], colors=['blue'], linewidths=3)\n",
    "    \n",
    "    # Plot data points\n",
    "    pos_mask = labels == 1\n",
    "    neg_mask = labels == 0\n",
    "    \n",
    "    ax.scatter(features_2d[pos_mask, 0], features_2d[pos_mask, 1], \n",
    "              c='green', label='Positive', alpha=0.8, s=120, edgecolors='darkgreen', linewidth=2)\n",
    "    ax.scatter(features_2d[neg_mask, 0], features_2d[neg_mask, 1], \n",
    "              c='red', label='Negative', alpha=0.8, s=120, edgecolors='darkred', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Word Count', fontsize=12)\n",
    "    ax.set_ylabel('Has Team', fontsize=12)\n",
    "    ax.set_title(f'{strategy_name}\\nAcc: {results[\"accuracy\"]:.1%}, Weights: [{results[\"weights\"][0]:.1f}, {results[\"weights\"][1]:.1f}, {results[\"weights\"][2]:.1f}]', \n",
    "                fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "plt.suptitle('Decision Boundaries for Different Weight Strategies', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Different weights create different decision boundaries\")\n",
    "print(\"- The boundary separates regions where the model predicts positive vs negative\")\n",
    "print(\"- Better weights create boundaries that better separate the actual classes\")\n",
    "print(\"- The blue regions predict positive sentiment, red regions predict negative\")\n",
    "print(\"- This visualization shows why feature engineering and weight learning matter!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 Solution: From Dot Products to Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the full pipeline: Features → Dot Product → Activation → Prediction\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function: maps any real number to (0,1)\"\"\"\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip to prevent overflow\n",
    "\n",
    "def analyze_full_pipeline(features: np.ndarray, weights: np.ndarray, text: str):\n",
    "    \"\"\"\n",
    "    Show the complete transformation from text to prediction.\n",
    "    \"\"\"\n",
    "    # Step 1: Feature extraction (already done)\n",
    "    print(f\"Input text: '{text}'\")\n",
    "    print(f\"Step 1 - Features: {features}\")\n",
    "    \n",
    "    # Step 2: Dot product (linear combination)\n",
    "    dot_product = np.dot(features, weights)\n",
    "    print(f\"Step 2 - Dot product: {features} · {weights} = {dot_product:.3f}\")\n",
    "    print(f\"         Calculation: {features[0]}×{weights[0]:.1f} + {features[1]}×{weights[1]:.1f} + {features[2]}×{weights[2]:.1f} = {dot_product:.3f}\")\n",
    "    \n",
    "    # Step 3: Activation function (sigmoid)\n",
    "    probability = sigmoid(dot_product)\n",
    "    print(f\"Step 3 - Sigmoid: σ({dot_product:.3f}) = 1/(1+e^(-{dot_product:.3f})) = {probability:.3f}\")\n",
    "    \n",
    "    # Step 4: Final prediction\n",
    "    prediction = 1 if probability > 0.5 else 0\n",
    "    confidence = probability if prediction == 1 else (1 - probability)\n",
    "    sentiment = \"POSITIVE\" if prediction == 1 else \"NEGATIVE\"\n",
    "    \n",
    "    print(f\"Step 4 - Final prediction: {sentiment} (confidence: {confidence:.1%})\")\n",
    "    \n",
    "    # Additional analysis\n",
    "    if dot_product > 2:\n",
    "        print(f\"         Note: High dot product ({dot_product:.3f}) → Very confident positive\")\n",
    "    elif dot_product > 0.5:\n",
    "        print(f\"         Note: Moderate dot product ({dot_product:.3f}) → Confident positive\")\n",
    "    elif dot_product > -0.5:\n",
    "        print(f\"         Note: Near-zero dot product ({dot_product:.3f}) → Uncertain prediction\")\n",
    "    else:\n",
    "        print(f\"         Note: Negative dot product ({dot_product:.3f}) → Confident negative\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return dot_product, probability, prediction\n",
    "\n",
    "# Test with our best-performing weights\n",
    "best_strategy = ranked_strategies[0]\n",
    "best_weights = best_strategy[1]['weights']\n",
    "\n",
    "print(f\"FULL PIPELINE ANALYSIS - Using '{best_strategy[0]}' strategy\")\n",
    "print(f\"Weights: {best_weights}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Analyze several key examples\n",
    "key_examples = [\n",
    "    (features[0], texts[0]),  # \"Go Dolphins!\"\n",
    "    (features[1], texts[1]),  # \"Terrible game\"\n",
    "    (features[2], texts[2]),  # \"Love the fins!\"\n",
    "    (features[4], texts[4]),  # \"Great win!!\"\n",
    "    (features[7], texts[7]),  # \"Worst season ever\"\n",
    "]\n",
    "\n",
    "pipeline_results = []\n",
    "for feature_vec, text in key_examples:\n",
    "    dot_prod, prob, pred = analyze_full_pipeline(feature_vec, best_weights, text)\n",
    "    pipeline_results.append((dot_prod, prob, pred))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore how the sigmoid function transforms dot products\n",
    "# Create comprehensive visualization showing the transformation\n",
    "\n",
    "# Generate range of dot product values\n",
    "dot_product_range = np.linspace(-4, 4, 200)\n",
    "sigmoid_values = sigmoid(dot_product_range)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Sigmoid function\n",
    "axes[0, 0].plot(dot_product_range, sigmoid_values, 'b-', linewidth=3, label='Sigmoid function')\n",
    "axes[0, 0].axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Decision threshold')\n",
    "axes[0, 0].axvline(x=0, color='r', linestyle='--', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Dot Product Value')\n",
    "axes[0, 0].set_ylabel('Probability')\n",
    "axes[0, 0].set_title('Sigmoid Activation Function')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Add annotations\n",
    "axes[0, 0].annotate('Positive predictions\\n(probability > 0.5)', xy=(2, 0.88), \n",
    "                xytext=(2.5, 0.9), fontsize=10,\n",
    "                arrowprops=dict(arrowstyle='->', color='green', alpha=0.7))\n",
    "axes[0, 0].annotate('Negative predictions\\n(probability < 0.5)', xy=(-2, 0.12), \n",
    "                xytext=(-3, 0.1), fontsize=10,\n",
    "                arrowprops=dict(arrowstyle='->', color='red', alpha=0.7))\n",
    "axes[0, 0].annotate('Uncertain\\n(≈ 0.5)', xy=(0, 0.5), \n",
    "                xytext=(0.5, 0.3), fontsize=10,\n",
    "                arrowprops=dict(arrowstyle='->', color='orange', alpha=0.7))\n",
    "\n",
    "# Plot 2: Our actual data points on the sigmoid curve\n",
    "all_dot_products = []\n",
    "all_probabilities = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    dot_prod = np.dot(features[i], best_weights)\n",
    "    prob = sigmoid(dot_prod)\n",
    "    all_dot_products.append(dot_prod)\n",
    "    all_probabilities.append(prob)\n",
    "    all_labels.append(labels[i])\n",
    "\n",
    "# Plot sigmoid curve\n",
    "axes[0, 1].plot(dot_product_range, sigmoid_values, 'b-', linewidth=2, alpha=0.5, label='Sigmoid function')\n",
    "axes[0, 1].axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Decision threshold')\n",
    "\n",
    "# Plot our data points\n",
    "pos_mask = np.array(all_labels) == 1\n",
    "neg_mask = np.array(all_labels) == 0\n",
    "\n",
    "axes[0, 1].scatter(np.array(all_dot_products)[pos_mask], np.array(all_probabilities)[pos_mask], \n",
    "               c='green', s=120, label='Positive tweets', alpha=0.8, edgecolors='darkgreen', linewidth=2)\n",
    "axes[0, 1].scatter(np.array(all_dot_products)[neg_mask], np.array(all_probabilities)[neg_mask], \n",
    "               c='red', s=120, label='Negative tweets', alpha=0.8, edgecolors='darkred', linewidth=2)\n",
    "\n",
    "# Add text labels for some points\n",
    "for i, text in enumerate(texts[:5]):\n",
    "    short_text = text[:10] + '..' if len(text) > 12 else text\n",
    "    axes[0, 1].annotate(short_text, (all_dot_products[i], all_probabilities[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.7)\n",
    "\n",
    "axes[0, 1].set_xlabel('Dot Product Value')\n",
    "axes[0, 1].set_ylabel('Probability')\n",
    "axes[0, 1].set_title('Our Tweets on the Sigmoid Curve')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: Distribution of dot products\n",
    "axes[1, 0].hist(np.array(all_dot_products)[pos_mask], bins=6, alpha=0.7, color='green', \n",
    "            label=f'Positive tweets (n={np.sum(pos_mask)})', edgecolor='darkgreen', linewidth=2)\n",
    "axes[1, 0].hist(np.array(all_dot_products)[neg_mask], bins=6, alpha=0.7, color='red', \n",
    "            label=f'Negative tweets (n={np.sum(neg_mask)})', edgecolor='darkred', linewidth=2)\n",
    "axes[1, 0].axvline(x=0, color='black', linestyle='--', alpha=0.7, label='Zero line')\n",
    "axes[1, 0].set_xlabel('Dot Product Value')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Distribution of Dot Products')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Sigmoid derivative (shows where learning is most effective)\n",
    "sigmoid_derivative = sigmoid_values * (1 - sigmoid_values)\n",
    "axes[1, 1].plot(dot_product_range, sigmoid_derivative, 'purple', linewidth=3, label='Sigmoid derivative')\n",
    "axes[1, 1].set_xlabel('Dot Product Value')\n",
    "axes[1, 1].set_ylabel('Derivative Value')\n",
    "axes[1, 1].set_title('Sigmoid Derivative (Learning Rate)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# Mark where our data points are on the derivative\n",
    "for i, dot_prod in enumerate(all_dot_products[:5]):\n",
    "    deriv_val = sigmoid(dot_prod) * (1 - sigmoid(dot_prod))\n",
    "    color = 'green' if all_labels[i] == 1 else 'red'\n",
    "    axes[1, 1].scatter(dot_prod, deriv_val, c=color, s=60, alpha=0.7, edgecolors='black')\n",
    "\n",
    "axes[1, 1].annotate('Steepest gradient\\n(fastest learning)', xy=(0, 0.25), \n",
    "                   xytext=(1, 0.2), fontsize=10,\n",
    "                   arrowprops=dict(arrowstyle='->', color='purple', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights about the Sigmoid Function:\")\n",
    "print(\"1. Maps any dot product value to a probability between 0 and 1\")\n",
    "print(\"2. Values > 0 become probabilities > 0.5 (positive predictions)\")\n",
    "print(\"3. Values < 0 become probabilities < 0.5 (negative predictions)\")\n",
    "print(\"4. Extreme values get 'squashed' - very confident predictions\")\n",
    "print(\"5. Values near 0 become probabilities near 0.5 - uncertain predictions\")\n",
    "print(\"6. The derivative shows where gradient descent learns fastest (around 0)\")\n",
    "print(\"\\nThis transformation is crucial for converting raw dot products into meaningful probabilities!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "**What we accomplished in Problem 2:**\n",
    "\n",
    "1. ✅ **Manual dot product calculation** - Built intuition through step-by-step arithmetic\n",
    "2. ✅ **Geometric interpretation** - Understood how vector alignment affects predictions\n",
    "3. ✅ **Weight strategy comparison** - Saw how different weights create different decision patterns\n",
    "4. ✅ **Full prediction pipeline** - Connected dot products to final predictions via sigmoid\n",
    "\n",
    "**Key insights discovered:**\n",
    "\n",
    "1. **Dot products measure alignment** between feature vectors and learned weight vectors\n",
    "2. **Geometric intuition matters** - angles between vectors determine prediction strength\n",
    "3. **Different weights create different decision boundaries** - this is what learning optimizes\n",
    "4. **The sigmoid function** transforms raw scores into probabilities for decision-making\n",
    "5. **Weight strategies reveal domain knowledge** - team mentions and excitement indicators work best for sports sentiment\n",
    "\n",
    "**Connection to the bigger picture:**\n",
    "- Every neural network operation fundamentally relies on dot products\n",
    "- The geometric interpretation helps debug and understand model behavior\n",
    "- This mathematical foundation scales from simple classifiers to ChatGPT\n",
    "\n",
    "**Ready for Problem 3: Loss Functions!**\n",
    "Now that we can make predictions, we need to learn how to measure and optimize their quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}